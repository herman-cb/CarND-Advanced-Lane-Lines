{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chessboard corners of file: ./camera_cal/calibration10.jpg\n",
      "Chessboard corners of file: ./camera_cal/calibration11.jpg\n",
      "Chessboard corners of file: ./camera_cal/calibration12.jpg\n",
      "Chessboard corners of file: ./camera_cal/calibration13.jpg\n",
      "Chessboard corners of file: ./camera_cal/calibration14.jpg\n",
      "Chessboard corners of file: ./camera_cal/calibration15.jpg\n",
      "Chessboard corners of file: ./camera_cal/calibration16.jpg\n",
      "Chessboard corners of file: ./camera_cal/calibration17.jpg\n",
      "Chessboard corners of file: ./camera_cal/calibration18.jpg\n",
      "Chessboard corners of file: ./camera_cal/calibration19.jpg\n",
      "Chessboard corners of file: ./camera_cal/calibration2.jpg\n",
      "Chessboard corners of file: ./camera_cal/calibration20.jpg\n",
      "Chessboard corners of file: ./camera_cal/calibration3.jpg\n",
      "Chessboard corners of file: ./camera_cal/calibration6.jpg\n",
      "Chessboard corners of file: ./camera_cal/calibration7.jpg\n",
      "Chessboard corners of file: ./camera_cal/calibration8.jpg\n",
      "Chessboard corners of file: ./camera_cal/calibration9.jpg\n"
     ]
    }
   ],
   "source": [
    "# Calibration of camera\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "objpoints = []\n",
    "imgpoints = []\n",
    "\n",
    "images = glob.glob(\"./camera_cal/calibration*.jpg\")\n",
    "\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "    \n",
    "    if ret:\n",
    "        print(\"Chessboard corners of file: {}\".format(fname))\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "        \n",
    "        \n",
    "        cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        ofname = \"output_images/with_corners{}.jpg\".format(idx)\n",
    "        cv2.imwrite(ofname, img)\n",
    "        \n",
    "img = cv2.imread(\"./camera_cal/calibration1.jpg\")  # To get the image shape\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "\n",
    "dist_mtx = {}\n",
    "dist_mtx[\"mtx\"] = mtx\n",
    "dist_mtx[\"dist\"] = dist\n",
    "pickle.dump(dist_mtx, open(\"./camera_cal/calibration_pickle.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tracker\n",
    "class Tracker:\n",
    "    def __init__(self, window_w, window_h, margin, ym=1, xm=1, smooth_factor=15):\n",
    "        self.window_w = window_w\n",
    "        self.window_h = window_h\n",
    "        self.margin = margin\n",
    "        self.ym_per_pixel = ym\n",
    "        self.xm_per_pixel = xm\n",
    "        self.smooth_factor = smooth_factor\n",
    "        self.recent_centers = []\n",
    "        \n",
    "    def find_window_centroids(self, warped):\n",
    "        window_w = self.window_w\n",
    "        window_h = self.window_h\n",
    "        margin = self.margin\n",
    "        \n",
    "        window_centroids= []\n",
    "        window = np.ones(window_w)\n",
    "        \n",
    "        l_sum = np.sum(warped[int(3*warped.shape[0]/4):, :int(warped.shape[1]/2)], axis = 0)\n",
    "        l_center = np.argmax(np.convolve(window, l_sum))-window_w/2\n",
    "        r_sum = np.sum(warped[int(3*warped.shape[0]/4):, int(warped.shape[1]/2):], axis = 0)\n",
    "        r_center = np.argmax(np.convolve(window, r_sum))-window_w/2+int(warped.shape[1]/2)\n",
    "        \n",
    "        window_centroids.append((l_center, r_center))\n",
    "        \n",
    "        for level in range(1, int(warped.shape[0]/window_h)):\n",
    "            image_layer = np.sum(warped[int(warped.shape[0]-(level+1)*window_h):int(warped.shape[0]-level*window_h),:],\n",
    "                                 axis=0)\n",
    "            conv_signal = np.convolve(window, image_layer)\n",
    "            offset = window_w/2\n",
    "            l_min_index = int(max(l_center+offset-margin, 0))\n",
    "            l_max_index = int(min(l_center+offset+margin, warped.shape[1]))\n",
    "            l_center = np.argmax(conv_signal[l_min_index:l_max_index])+l_min_index-offset\n",
    "            \n",
    "            r_min_index = int(max(r_center+offset-margin, 0))\n",
    "            r_max_index = int(min(r_center+offset+margin, warped.shape[1]))\n",
    "            r_center = np.argmax(conv_signal[r_min_index:r_max_index])+r_min_index-offset\n",
    "            \n",
    "            window_centroids.append((l_center, r_center))\n",
    "        self.recent_centers.append(window_centroids)\n",
    "        \n",
    "        return np.average(self.recent_centers[-self.smooth_factor:], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "\n",
    "\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate directional gradient\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    elif orient == 'y':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    else:\n",
    "        raise Error(\"Unsupported direction for gradient\")\n",
    "    # Apply threshold\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    abs_sobel = np.uint8(255 * abs_sobel / np.max(abs_sobel))\n",
    "    grad_binary = np.zeros_like(abs_sobel)\n",
    "    grad_binary[(abs_sobel >= thresh[0]) & (abs_sobel <= thresh[1])] = 1\n",
    "    return grad_binary\n",
    "\n",
    "def hls_thresh(img, sthresh=(0, 255), vthresh=(0, 255)):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "    s_output = np.zeros_like(s_channel)\n",
    "    s_output[(s_channel > sthresh[0]) & (s_channel <= sthresh[1])] = 1\n",
    "    \n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    v_channel = hls[:,:,2]\n",
    "    v_output = np.zeros_like(v_channel)\n",
    "    v_output[(v_channel > vthresh[0]) & (v_channel <= vthresh[1])] = 1\n",
    "        \n",
    "    output = np.zeros_like(s_channel)\n",
    "    output[(s_output == 1) & (v_output == 1)] = 1\n",
    "        \n",
    "    return output\n",
    "\n",
    "def window_mask(w, h, img_ref, center, level):\n",
    "    out = np.zeros_like(img_ref)\n",
    "    out[int(img_ref.shape[0]-(level+1)*h):int(img_ref.shape[0]-level*h),\n",
    "        max(0,int(center-w)):min(int(center+w), img_ref.shape[1])] = 1\n",
    "    return out\n",
    "\n",
    "# TODO: Insert color threasholding based on HSV here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hermansahota/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/__main__.py:87: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/hermansahota/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/__main__.py:91: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Undistort test images\n",
    "\n",
    "mtx = dist_mtx[\"mtx\"]\n",
    "dist = dist_mtx[\"dist\"]\n",
    "\n",
    "\n",
    "images = glob.glob(\"./test_images/test*.jpg\")\n",
    "\n",
    "for idx,fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    \n",
    "    preProcessImage = np.zeros_like(img[:,:,0])\n",
    "    gradx = abs_sobel_thresh(img, orient='x', thresh=(12, 255))\n",
    "    grady = abs_sobel_thresh(img, orient='y', thresh=(25, 255))\n",
    "    c_binary = hls_thresh(img, sthresh=(100, 255), vthresh=(50, 255))\n",
    "    preProcessImage[(gradx == 1) & (grady == 1) | (c_binary == 1)] = 255\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Perspective transform area\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    bot_width = 0.76\n",
    "    mid_width = 0.08\n",
    "    height_pct = 0.62\n",
    "    bottom_trim = 0.935\n",
    "\n",
    "    \n",
    "    src= np.float32([[img.shape[1]*(0.5- mid_width/2), img.shape[0]*height_pct],\n",
    "                     [img.shape[1]*(0.5+ mid_width/2), img.shape[0]*height_pct],\n",
    "                     [img.shape[1]*(0.5+bot_width/2), img.shape[0]-bottom_trim],\n",
    "                    [img.shape[1]*(0.5-bot_width/2), img.shape[0]-bottom_trim]])\n",
    "\n",
    "    offset = img_size[0]*0.25\n",
    "        \n",
    "    dst = np.float32([[offset, 0],\n",
    "                      [img_size[0]-offset, 0], \n",
    "                      [img_size[0]-offset, img_size[1]], \n",
    "                      [offset, img_size[1]]])\n",
    "\n",
    "#     print(\"src = {}\".format(src))\n",
    "#     print(\"dst = {}\".format(dst))\n",
    "    \n",
    "                     \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    warped = cv2.warpPerspective(preProcessImage, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    window_w = 25\n",
    "    window_h = 80\n",
    "    \n",
    "    tracker = Tracker(window_w, window_h, margin=25, ym=10/720., xm=4/384., smooth_factor=15)\n",
    "    xm_per_pix = tracker.xm_per_pixel\n",
    "    ym_per_pix = tracker.ym_per_pixel\n",
    "    window_centroids = tracker.find_window_centroids(warped)\n",
    "    \n",
    "    l_points = np.zeros_like(warped)\n",
    "    r_points = np.zeros_like(warped)\n",
    "    \n",
    "    leftx = []\n",
    "    rightx = []\n",
    "    for level in range(0, len(window_centroids)):\n",
    "        \n",
    "        leftx.append(window_centroids[level][0])\n",
    "        rightx.append(window_centroids[level][1])\n",
    "        l_mask = window_mask(window_w, window_h, warped, window_centroids[level][0], level)\n",
    "        r_mask = window_mask(window_w, window_h, warped, window_centroids[level][1], level)\n",
    "        \n",
    "        l_points[(l_points == 255) | (l_mask == 1)] = 255\n",
    "        r_points[(r_points == 255) | (r_mask == 1)] = 255\n",
    "        \n",
    "    \n",
    "    template = np.array(r_points+l_points, np.uint8)\n",
    "    zero_channel = np.zeros_like(template)\n",
    "    template = np.array(cv2.merge((zero_channel, template, zero_channel)), np.uint8)\n",
    "    warpage = np.array(cv2.merge((warped, warped, warped)), np.uint8)\n",
    "    result = cv2.addWeighted(warpage, 1, template, 0.5, 0.0)\n",
    "    \n",
    "    \n",
    "    yvals = range(0, warped.shape[0])\n",
    "    res_yvals = np.arange(warped.shape[0]-(window_h/2), 0, -window_h)\n",
    "    \n",
    "    left_fit = np.polyfit(res_yvals, leftx, 2)\n",
    "    left_fitx = left_fit[0]*yvals*yvals + left_fit[1]*yvals + left_fit[2]\n",
    "    left_fitx = np.array(left_fitx, np.int32)\n",
    "    \n",
    "    right_fit = np.polyfit(res_yvals, rightx, 2)\n",
    "    right_fitx = right_fit[0]*yvals*yvals + right_fit[1]*yvals + right_fit[2]\n",
    "    right_fitx = np.array(right_fitx, np.int32)\n",
    "    \n",
    "    left_lane = np.array(list(zip(np.concatenate((left_fitx-window_w/2, left_fitx[::-1]+window_w/2), axis=0),\n",
    "                                 np.concatenate((yvals, yvals[::-1]), axis=0))), np.int32)\n",
    "    right_lane = np.array(list(zip(np.concatenate((right_fitx-window_w/2, right_fitx[::-1]+window_w/2), axis=0),\n",
    "                                 np.concatenate((yvals, yvals[::-1]), axis=0))), np.int32)\n",
    "    middle_marker = np.array(list(zip(np.concatenate((left_fitx+window_w/2, right_fitx[::-1]-window_w/2), axis=0),\n",
    "                                 np.concatenate((yvals, yvals[::-1]), axis=0))), np.int32)\n",
    "    \n",
    "    \n",
    "#     print(\"left_lane.shape = {}\".format(right_lane))\n",
    "    road = np.zeros_like(img)\n",
    "#     road_bkg = np.zeros_like(img)\n",
    "    \n",
    "    cv2.fillPoly(road, [left_lane], color=[255, 0, 0])\n",
    "    cv2.fillPoly(road, [right_lane], color=[0, 0, 255])\n",
    "    cv2.fillPoly(road, [middle_marker], color=[0, 255, 0])\n",
    "    cv2.fillPoly(road_bkg, [left_lane], color=[255, 255, 255])\n",
    "    cv2.fillPoly(road_bkg, [right_lane], color=[255, 255, 255])\n",
    "    \n",
    "    road_warped = cv2.warpPerspective(road, Minv, img_size, flags=cv2.INTER_LINEAR)\n",
    "    road_warped_bkg = cv2.warpPerspective(road_bkg, Minv, img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    base = cv2.addWeighted(img, 1.0, road_warped_bkg, -1.0, 0.0)\n",
    "    result = cv2.addWeighted(img, 1.0, road_warped, 1.0, 0.0)\n",
    "    \n",
    "    \n",
    "    camera_center = (left_fitx[-1] + right_fitx[-1])/2\n",
    "    center_diff = (camera_center-warped.shape[1]/2)*xm_per_pix\n",
    "    side_pos = 'left'\n",
    "    if center_diff <= 0:\n",
    "        side_pos = 'right'\n",
    "        \n",
    "        \n",
    "    curve_fit_cr = np.polyfit(np.array(res_yvals, np.float32)*ym_per_pix,\n",
    "                             np.array(leftx, np.float32)*xm_per_pix, 2)\n",
    "    curverad = ((1 + \\\n",
    "                 (2*curve_fit_cr[0]*yvals[-1]*ym_per_pix + curve_fit_cr[1])**2)**1.5)/np.absolute(2*curve_fit_cr[0])\n",
    "#     print(\"curverad = {}\".format(curverad))\n",
    "    cv2.putText(result, 'Radius of curvature {} m'.format(round(curverad,3)), \n",
    "                (50, 50), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                1, \n",
    "                (255, 255, 255), \n",
    "                2)\n",
    "    cv2.putText(result, 'Position: {} of center by {} m'.format(side_pos, round(center_diff,3)), \n",
    "                (50, 100), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                1, \n",
    "                (255, 255, 255), \n",
    "                2)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    ofname = \"./test_images/tracked{}.jpg\".format(idx+1)  #Test index are 1 based\n",
    "    cv2.imwrite(ofname, result)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "\n",
    "def mag_thresh(image, sobel_kernel=3, thresh=(0, 255)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate directional gradient\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    sobel = np.sqrt(sobelx**2 + sobely**2)\n",
    "    scaled_sobel = np.uint8(255 * sobel / np.max(sobel))\n",
    "    mag_binary = np.zeros_like(scaled_sobel)\n",
    "    mag_binary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    return mag_binary\n",
    "\n",
    "def dir_threshold(image, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate directional gradient\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    sobel_dir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    dir_binary = np.zeros_like(sobel_dir)\n",
    "    dir_binary[(sobel_dir >= thresh[0]) & (sobel_dir <= thresh[1])] = 1\n",
    "    return dir_binary\n",
    "\n",
    "\n",
    "def hls_select(img, thresh=(0, 255)):\n",
    "    # 1) Convert to HLS color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    # 2) Apply a threshold to the S channel\n",
    "    s = hls[:,:,2]\n",
    "    binary_output = np.zeros_like(s)\n",
    "    binary_output[(s>thresh[0]) & (s<=thresh[1])] = 1\n",
    "    # 3) Return a binary image of threshold result\n",
    "    return binary_output\n",
    "\n",
    "def pipeline(img, s_thresh=(170, 255), sx_thresh=(20, 100)):\n",
    "    img = np.copy(img)\n",
    "    # Convert to HSV color space and separate the V channel\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    l_channel = hsv[:,:,1]\n",
    "    s_channel = hsv[:,:,2]\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    # Stack each channel\n",
    "    # Note color_binary[:, :, 0] is all 0s, effectively an all black image. It might\n",
    "    # be beneficial to replace this channel with something else.\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary))\n",
    "    return color_binary\n",
    "\n",
    "\n",
    "image = mpimg.imread(\"signs_vehicles_xygrad.jpg\")\n",
    "\n",
    "pipeline_binary = pipeline(image)\n",
    "\n",
    "# Choose a Sobel kernel size\n",
    "ksize = 3 # Choose a larger odd number to smooth gradient measurements\n",
    "\n",
    "# Apply each of the thresholding functions\n",
    "gradx = abs_sobel_thresh(image, orient='x', sobel_kernel=ksize, thresh=(20, 100))\n",
    "grady = abs_sobel_thresh(image, orient='y', sobel_kernel=ksize, thresh=(20, 100))\n",
    "mag_binary = mag_thresh(image, sobel_kernel=ksize, thresh=(20, 100))\n",
    "dir_binary = dir_threshold(image, sobel_kernel=ksize, thresh=(0.7, 1.3))\n",
    "\n",
    "hls_binary = hls_select(image, thresh=(90, 255))\n",
    "\n",
    "combined = np.zeros_like(dir_binary)\n",
    "combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# ax1.imshow(gray, cmap='gray')\n",
    "ax1.imshow(image)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(combined, cmap='gray')\n",
    "ax2.set_title('Combined Gradient', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
